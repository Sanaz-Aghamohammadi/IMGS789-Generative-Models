{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ========================\n",
    "# 1. Hyperparameters and Configuration\n",
    "# ========================\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "tf.random.set_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "\n",
    "# Hyperparameters\n",
    "dataroot = 'data'\n",
    "batch_size = 128\n",
    "image_size = 64  # Resize CIFAR-10 images to 64x64\n",
    "nc = 3          # Number of channels in the training images (CIFAR-10 is RGB)\n",
    "nz = 100        # Size of z latent vector (i.e., size of generator input)\n",
    "ngf = 64        # Size of feature maps in generator\n",
    "ndf = 64        # Size of feature maps in discriminator\n",
    "num_epochs = 50\n",
    "lr = 0.0001\n",
    "beta1 = 0.5     # Beta1 hyperparam for Adam optimizers\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('dcgan_results', exist_ok=True)\n",
    "\n",
    "# ========================\n",
    "# 2. Data Loading and Preprocessing\n",
    "# ========================\n",
    "\n",
    "# Load the dataset\n",
    "(train_images, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess(image):\n",
    "    image = tf.cast(image, tf.float32)  # Cast to float32\n",
    "    # Resize to 64x64\n",
    "    image = tf.image.resize(image, [image_size, image_size])\n",
    "    # Normalize to [-1, 1]\n",
    "    image = (image - 127.5) / 127.5\n",
    "    return image\n",
    "\n",
    "# Create a tf.data.Dataset and apply preprocessing\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(50000).batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# ========================\n",
    "# 3. Define the Generator Network\n",
    "# ========================\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Input is Z, going into a dense layer\n",
    "    model.add(layers.Dense(4*4*ngf*8, use_bias=False, input_shape=(nz,)))\n",
    "    model.add(layers.Reshape((4, 4, ngf*8)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    # (4x4xngf*8) -> (8x8xngf*4)\n",
    "    model.add(layers.Conv2DTranspose(ngf*4, kernel_size=4, strides=2, padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    # (8x8xngf*4) -> (16x16xngf*2)\n",
    "    model.add(layers.Conv2DTranspose(ngf*2, kernel_size=4, strides=2, padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    # (16x16xngf*2) -> (32x32xngf)\n",
    "    model.add(layers.Conv2DTranspose(ngf, kernel_size=4, strides=2, padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    # (32x32xngf) -> (64x64xnc)\n",
    "    model.add(layers.Conv2DTranspose(nc, kernel_size=4, strides=2, padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the generator\n",
    "generator = make_generator_model()\n",
    "\n",
    "# ========================\n",
    "# 4. Define the Discriminator Network\n",
    "# ========================\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Input is (64x64xnc)\n",
    "    model.add(layers.Conv2D(ndf, kernel_size=4, strides=2, padding='same', input_shape=[image_size, image_size, nc]))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # (32x32xndf) -> (16x16xndf*2)\n",
    "    model.add(layers.Conv2D(ndf*2, kernel_size=4, strides=2, padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # (16x16xndf*2) -> (8x8xndf*4)\n",
    "    model.add(layers.Conv2D(ndf*4, kernel_size=4, strides=2, padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # (8x8xndf*4) -> (4x4xndf*8)\n",
    "    model.add(layers.Conv2D(ndf*8, kernel_size=4, strides=2, padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the discriminator\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# ========================\n",
    "# 5. Loss Function and Optimizers\n",
    "# ========================\n",
    "\n",
    "# Loss function\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta1)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta1)\n",
    "\n",
    "# Fixed noise vector for generating images\n",
    "fixed_noise = tf.random.normal([64, nz])\n",
    "\n",
    "# ========================\n",
    "# 6. Training Loop\n",
    "# ========================\n",
    "\n",
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# Training step function\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    noise = tf.random.normal([batch_size, nz])\n",
    "\n",
    "    # Label smoothing\n",
    "    real_labels = tf.ones((batch_size, 1)) * 0.9  # Real label smoothing\n",
    "    fake_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    # ---------------------\n",
    "    # Train Discriminator\n",
    "    # ---------------------\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        # Generate fake images\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        # Get discriminator outputs\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        # Calculate losses\n",
    "        d_loss_real = cross_entropy(real_labels, real_output)\n",
    "        d_loss_fake = cross_entropy(fake_labels, fake_output)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    # Compute gradients and update discriminator\n",
    "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # -----------------\n",
    "    # Train Generator\n",
    "    # -----------------\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        # Generator wants discriminator to think images are real\n",
    "        g_loss = cross_entropy(real_labels, fake_output)\n",
    "\n",
    "    # Compute gradients and update generator\n",
    "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    return d_loss, g_loss\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, image_batch in enumerate(train_dataset):\n",
    "        d_loss, g_loss = train_step(image_batch)\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(train_dataset)} '\n",
    "                  f'Loss D: {d_loss:.4f}, Loss G: {g_loss:.4f}')\n",
    "\n",
    "        # Save losses for plotting later\n",
    "        G_losses.append(g_loss.numpy())\n",
    "        D_losses.append(d_loss.numpy())\n",
    "\n",
    "        # Save generated images periodically\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(train_dataset) - 1)):\n",
    "            generated_images = generator(fixed_noise, training=False)\n",
    "            img_list.append(generated_images)\n",
    "        iters += 1\n",
    "\n",
    "# ========================\n",
    "# 7. Visualize the Results\n",
    "# ========================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"Generator\")\n",
    "plt.plot(D_losses, label=\"Discriminator\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('dcgan_results/loss_curves.png')\n",
    "plt.show()\n",
    "\n",
    "# Animation showing the improvements of the generator\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ims = []\n",
    "for images in img_list:\n",
    "    # Rescale images to [0,1] for display\n",
    "    images = (images + 1) / 2.0\n",
    "    grid = tf.concat([tf.concat([images[i*8 + j] for j in range(8)], axis=1) for i in range(8)], axis=0)\n",
    "    ims.append([plt.imshow(grid.numpy(), animated=True)])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=500, repeat_delay=1000, blit=True)\n",
    "\n",
    "# Save the animation as a GIF file\n",
    "ani.save('dcgan_results/generation_animation.gif', writer='pillow')\n",
    "print(\"Animation saved as 'dcgan_results/generation_animation.gif'.\")\n",
    "\n",
    "# Display real images\n",
    "sample_real_images = next(iter(train_dataset))\n",
    "sample_real_images = (sample_real_images + 1) / 2.0  # Rescale to [0,1]\n",
    "grid_real = tf.concat([tf.concat([sample_real_images[i*8 + j] for j in range(8)], axis=1) for i in range(8)], axis=0)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(grid_real.numpy())\n",
    "plt.savefig('dcgan_results/real_images.png')\n",
    "plt.show()\n",
    "\n",
    "# Display generated images from the last epoch\n",
    "generated_images = generator(fixed_noise, training=False)\n",
    "generated_images = (generated_images + 1) / 2.0  # Rescale to [0,1]\n",
    "grid_fake = tf.concat([tf.concat([generated_images[i*8 + j] for j in range(8)], axis=1) for i in range(8)], axis=0)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(grid_fake.numpy())\n",
    "plt.savefig(f'dcgan_results/fake_images_epoch_{num_epochs}.png')\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 8. Save the Trained Generator Model\n",
    "# ========================\n",
    "\n",
    "# Save the trained generator model\n",
    "generator.save('generator.h5')\n",
    "print(\"Generator model saved as 'generator.h5'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
